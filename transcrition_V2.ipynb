{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240930\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "print(whisper.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ffmpeg\n",
    "\n",
    "\n",
    "# 提取音频并保存为 WAV 格式\n",
    "ffmpeg.input(r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\Heizmann\\Heizmann_Interview record.mkv\").output(r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\Heizmann\\extracted_audio2.wav\", audio_bitrate='128k').run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "input_path = r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\trans\\Hans.mkv\"\n",
    "output_path = r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\trans\\Hans.mp3\"\n",
    "\n",
    "\n",
    "# 调用 FFmpeg 提取音频\n",
    "subprocess.call([\"ffmpeg\", \"-i\", input_path, \"temp_audio.wav\"])\n",
    "\n",
    "# 使用 pydub 处理提取的音频\n",
    "audio = AudioSegment.from_file(\"temp_audio.wav\", format=\"wav\")\n",
    "\n",
    "# 保存为 MP3 格式\n",
    "audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "os.remove(\"temp_audio.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "input_path = r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\trans\\Julia Anken.m4a\"\n",
    "output_path = r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\trans\\Julia Anken.mp3\"\n",
    "\n",
    "# 提取音频并保存为 WAV 格式\n",
    "ffmpeg.input(input_path).output(output_path, audio_bitrate='128k').run()\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# 调用 FFmpeg 提取音频\n",
    "subprocess.call([\"ffmpeg\", \"-i\", input_path, \"temp_audio.wav\"])\n",
    "\n",
    "# 使用 pydub 处理提取的音频\n",
    "audio = AudioSegment.from_file(\"temp_audio.wav\", format=\"wav\")\n",
    "\n",
    "# 保存为 MP3 格式\n",
    "audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "os.remove(\"temp_audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|███████████████████████████████████████▉| 3515.8/3516.469 [01:03<00:00, 55.28s/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转录结果已保存至 E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\trans\\transcription_result_Julia Anken.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import sys\n",
    "from tqdm import tqdm  # 导入 tqdm\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else None\n",
    "\n",
    "# 如果没有 GPU，抛出错误并中止\n",
    "if device is None:\n",
    "    print(\"错误：没有可用的 GPU。程序将中止。\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 加载 Whisper 模型并启用 CUDA 加速\n",
    "model = whisper.load_model(\"base\").to(device)  # 使用 'large' 模型，精度更高\n",
    "\n",
    "###############################\n",
    "# 路径设置\n",
    "###############################\n",
    "# 输入音频文件路径# 输出文件路径\n",
    "# audio_path = r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\tourism\\tourism.mp3\"  # 替换为你的音频文件路径\n",
    "# output_txt_path = r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\tourism\\transcription_result.txt\"  # 替换为你想保存的输出文件路径\n",
    "audio_path = r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\trans\\Hans.mp3\"  # 替换为你的音频文件路径\n",
    "output_txt_path = r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\trans\\Hans.txt\"  # 替换为你想保存的输出文件路径\n",
    "\n",
    "###############################\n",
    "# 处理音频并获取时长\n",
    "###############################\n",
    "# 使用 Whisper 加载音频文件\n",
    "audio = whisper.load_audio(audio_path)\n",
    "\n",
    "# Whisper 默认采样率\n",
    "sample_rate = 16000\n",
    "\n",
    "# 计算音频文件的时长（单位：秒）\n",
    "duration = len(audio) / sample_rate\n",
    "\n",
    "###############################\n",
    "# 转录音频并显示进度条\n",
    "###############################\n",
    "# 自定义带进度条的转录函数\n",
    "def transcribe_with_progress(model, audio_path, pbar):\n",
    "    # 清理 CUDA 缓存\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 启动 Whisper 的转录，禁用内置的默认进度条\n",
    "    result = model.transcribe(audio_path, language=\"en\")\n",
    "    for segment in result[\"segments\"]:\n",
    "        # 每处理一个段落，更新进度条\n",
    "        pbar.update(segment[\"end\"] - pbar.n)  # 以段落结束时间为更新基准\n",
    "    return result\n",
    "\n",
    "# 创建进度条并执行转录\n",
    "with tqdm(total=duration, unit=\"s\", desc=\"Transcribing\", ncols=100) as pbar:\n",
    "    result = transcribe_with_progress(model, audio_path, pbar)\n",
    "\n",
    "###############################\n",
    "# 保存转录结果\n",
    "###############################\n",
    "# 将结果保存为带时间戳和分段的文本\n",
    "with open(output_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for segment in result[\"segments\"]:\n",
    "        start = segment[\"start\"]\n",
    "        end = segment[\"end\"]\n",
    "        text = segment[\"text\"]\n",
    "        # 格式化输出时间戳和文字\n",
    "        f.write(f\"[{start:.2f}s - {end:.2f}s] {text}\\n\")\n",
    "\n",
    "print(f\"转录结果已保存至 {output_txt_path}\")\n",
    "\n",
    "# 清理 CUDA 缓存\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import sys\n",
    "from tqdm import tqdm  # 导入 tqdm\n",
    "from pyannote.audio import Pipeline  # 用于说话人分离\n",
    "from pyannote.core import Segment\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else None\n",
    "\n",
    "# 如果没有 GPU，抛出错误并中止\n",
    "if device is None:\n",
    "    print(\"错误：没有可用的 GPU。程序将中止。\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 加载 Whisper 模型并启用 CUDA 加速\n",
    "model = whisper.load_model(\"large\").to(device)  # 使用 'large' 模型，支持详细标点\n",
    "\n",
    "###############################\n",
    "# 路径设置\n",
    "###############################\n",
    "# 输入音频文件路径\n",
    "audio_path = r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\tourism\\tourism.mp3\"  # 替换为你的音频文件路径\n",
    "# 输出文件路径\n",
    "output_txt_path = r\"E:\\OneDrive - MSFT\\.master_data\\24-25ws\\SIL\\interview\\tourism\\transcription_result_with_speakers.txt\"  # 替换为你想保存的输出文件路径\n",
    "\n",
    "###############################\n",
    "# 使用 pyannote 进行说话人分离\n",
    "###############################\n",
    "# 使用 pyannote.audio 的预训练管道\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=\"你的HuggingFace令牌\")  # 需要 Hugging Face 账号\n",
    "\n",
    "# 运行说话人分离\n",
    "diarization = pipeline(audio_path)\n",
    "\n",
    "###############################\n",
    "# 使用 Whisper 转录音频\n",
    "###############################\n",
    "# 加载音频并计算时长\n",
    "audio = whisper.load_audio(audio_path)\n",
    "sample_rate = 16000\n",
    "duration = len(audio) / sample_rate\n",
    "\n",
    "# 自定义带进度条的转录函数\n",
    "def transcribe_with_progress(model, audio_path, pbar):\n",
    "    # 清理 CUDA 缓存\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 启动 Whisper 的转录，禁用内置的默认进度条\n",
    "    result = model.transcribe(audio_path, language=\"en\", progress_bar=False)\n",
    "    for segment in result[\"segments\"]:\n",
    "        # 每处理一个段落，更新进度条\n",
    "        pbar.update(segment[\"end\"] - pbar.n)  # 以段落结束时间为更新基准\n",
    "    return result\n",
    "\n",
    "# 创建进度条并执行转录\n",
    "with tqdm(total=duration, unit=\"s\", desc=\"Transcribing\", ncols=100) as pbar:\n",
    "    result = transcribe_with_progress(model, audio_path, pbar)\n",
    "\n",
    "###############################\n",
    "# 合并转录和说话人分离结果\n",
    "###############################\n",
    "# 将每段转录结果和说话人分段对齐\n",
    "def assign_speakers_to_segments(diarization, whisper_segments):\n",
    "    speaker_segments = []\n",
    "    for segment in whisper_segments:\n",
    "        start_time = segment[\"start\"]\n",
    "        end_time = segment[\"end\"]\n",
    "        text = segment[\"text\"]\n",
    "\n",
    "        # 查找说话人信息\n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            if turn.intersects(Segment(start_time, end_time)):\n",
    "                speaker_segments.append((speaker, start_time, end_time, text))\n",
    "                break\n",
    "    return speaker_segments\n",
    "\n",
    "# 获取合并结果\n",
    "merged_segments = assign_speakers_to_segments(diarization, result[\"segments\"])\n",
    "\n",
    "###############################\n",
    "# 保存结果到文件\n",
    "###############################\n",
    "# 将结果保存为带详细标点、时间戳、分段和说话人标注的文本\n",
    "with open(output_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for speaker, start, end, text in merged_segments:\n",
    "        f.write(f\"[{start:.2f}s - {end:.2f}s] {speaker}: {text}\\n\")\n",
    "\n",
    "print(f\"转录结果已保存至 {output_txt_path}\")\n",
    "\n",
    "# 清理 CUDA 缓存\n",
    "torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
